{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "!pip install ipython-autotime\n",
        "%load_ext autotime"
      ],
      "metadata": {
        "id": "EtXfN7GWYa1x",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6f919c2-60d5-4976-a58c-582c9da79f59"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting ipython-autotime\n",
            "  Downloading ipython_autotime-0.3.1-py2.py3-none-any.whl (6.8 kB)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.8/dist-packages (from ipython-autotime) (7.9.0)\n",
            "Requirement already satisfied: pexpect in /usr/local/lib/python3.8/dist-packages (from ipython->ipython-autotime) (4.8.0)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.8/dist-packages (from ipython->ipython-autotime) (0.7.5)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.8/dist-packages (from ipython->ipython-autotime) (5.7.1)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.8/dist-packages (from ipython->ipython-autotime) (57.4.0)\n",
            "Requirement already satisfied: backcall in /usr/local/lib/python3.8/dist-packages (from ipython->ipython-autotime) (0.2.0)\n",
            "Requirement already satisfied: prompt-toolkit<2.1.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from ipython->ipython-autotime) (2.0.10)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.8/dist-packages (from ipython->ipython-autotime) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from ipython->ipython-autotime) (4.4.2)\n",
            "Collecting jedi>=0.10\n",
            "  Downloading jedi-0.18.2-py2.py3-none-any.whl (1.6 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m26.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: parso<0.9.0,>=0.8.0 in /usr/local/lib/python3.8/dist-packages (from jedi>=0.10->ipython->ipython-autotime) (0.8.3)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->ipython-autotime) (0.2.5)\n",
            "Requirement already satisfied: six>=1.9.0 in /usr/local/lib/python3.8/dist-packages (from prompt-toolkit<2.1.0,>=2.0.0->ipython->ipython-autotime) (1.15.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.8/dist-packages (from pexpect->ipython->ipython-autotime) (0.7.0)\n",
            "Installing collected packages: jedi, ipython-autotime\n",
            "Successfully installed ipython-autotime-0.3.1 jedi-0.18.2\n",
            "time: 490 µs (started: 2023-01-06 21:25:47 +00:00)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip /content/drive/MyDrive/Project/Face_Classification/face_images.zip -d /content/drive/MyDrive/Project/Face_Classification/Face_images\n"
      ],
      "metadata": {
        "id": "CtMKd8SXbNZG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import cv2 \n",
        "import glob\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np"
      ],
      "metadata": {
        "id": "Ru9E7Vh7qwkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_excel('/content/drive/MyDrive/Project/Face_Classification/(English translate)20210426_image_classification_Imbesideyou.xlsx')\n",
        "#renaming the column names\n",
        "df.rename(columns=df.iloc[0],inplace = True)\n",
        "#th row drop\n",
        "df.drop(df.index[0],inplace=True)\n",
        "print(df.columns)\n",
        "#dropping the first two columns\n",
        "df.drop(df.iloc[:, :2], axis=1,inplace=True)\n",
        "images = [] \n",
        "f_img = list(df['Mask: Y/N\\n\"-\" is not for face images'])\n",
        "person_id = list(df['Person ID'])\n",
        "pid=[]\n",
        "#print(f_img[0])\n",
        "c=0\n",
        "#giving the file path to read the files\n",
        "for file in glob.glob('/content/drive/MyDrive/Project/Face_Classification/Face_images/face_images/a055a66f-46ea-4c57-8de4-f3cc4f27c59c/*.jpg'):\n",
        "  if(f_img[c]=='N'):\n",
        "    ig = cv2.imread(file)\n",
        "    res = cv2.resize(ig, dsize=(32, 32), interpolation=cv2.INTER_CUBIC)\n",
        "    images.append(res)\n",
        "    pid.append(person_id[c])  #loading images from the givin file\n",
        "  c=c+1\n",
        "for file in glob.glob('/content/drive/MyDrive/Project/Face_Classification/Face_images/face_images/dd40a338-faf9-481d-996c-6fe0f648d0b7/*.jpg'):\n",
        "  if(f_img[c]=='N'):\n",
        "    ig = cv2.imread(file)\n",
        "    res = cv2.resize(ig, dsize=(32, 32), interpolation=cv2.INTER_CUBIC)\n",
        "    images.append(res)\n",
        "    pid.append(person_id[c]) \n",
        "  c=c+1\n",
        "for file in glob.glob('/content/drive/MyDrive/Project/Face_Classification/Face_images/face_images/f5845e49-256f-4d70-9214-47bd5358c9d1/*.jpg'):\n",
        "  if(f_img[c]=='N'):\n",
        "    ig = cv2.imread(file)\n",
        "    res = cv2.resize(ig, dsize=(32, 32), interpolation=cv2.INTER_CUBIC)\n",
        "    images.append(res)\n",
        "    pid.append(person_id[c]) \n",
        "  c=c+1\n",
        "#df.head()\n",
        "\n",
        "print(len(images))\n",
        "print(images[0].shape)\n",
        "print(len(pid))\n",
        "print(c)\n",
        "# plt.imshow(images[0],cmap=\"gray\")"
      ],
      "metadata": {
        "id": "RupE8Y0Gse5s",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ef340074-0a26-457e-c796-a4ea590608ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Index([nan, 'NO', 'File name', 'Person ID',\n",
            "       'Mask: Y/N\\n\"-\" is not for face images'],\n",
            "      dtype='object')\n",
            "30082\n",
            "(32, 32, 3)\n",
            "30082\n",
            "57898\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import collections\n",
        "# pid = np.array(pid)\n",
        "# np.unique(pid)\n",
        "collections.Counter(pid)"
      ],
      "metadata": {
        "id": "3kNg5qXf3zWN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "689650fe-623c-4538-d313-517361e564c8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Counter({1.0: 8924, 4.0: 7460, 3.0: 5971, 2.0: 7727})"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "imgs = np.array(images)\n",
        "x = imgs.astype('float32') / 255.0 - 0.5\n",
        "# X_train, X_test, y_train, y_test = train_test_split(images, ids, test_size=0.3, random_state=42)"
      ],
      "metadata": {
        "id": "6ARbKkID_hKk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras.models import save_model\n",
        "import tensorflow.keras.layers\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from keras.layers import Input, Conv2D, MaxPooling2D, UpSampling2D, Dense\n",
        "from keras.models import Model\n",
        "\n",
        "\n",
        "    # encoder\n",
        "encoder = tensorflow.keras.models.Sequential()\n",
        "encoder.add(tensorflow.keras.layers.InputLayer((32, 32, 3)))\n",
        "    \n",
        "encoder.add(tensorflow.keras.layers.Conv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "encoder.add(tensorflow.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "encoder.add(tensorflow.keras.layers.Conv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "encoder.add(tensorflow.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "encoder.add(tensorflow.keras.layers.Conv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "encoder.add(tensorflow.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "encoder.add(tensorflow.keras.layers.Conv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same'))\n",
        "encoder.add(tensorflow.keras.layers.MaxPooling2D(pool_size=(2, 2)))\n",
        "encoder.add(tensorflow.keras.layers.Flatten())\n",
        "encoder.add(tensorflow.keras.layers.Dense(128))\n",
        "\n",
        "    # decoder\n",
        "decoder = tensorflow.keras.models.Sequential()\n",
        "decoder.add(tensorflow.keras.layers.InputLayer((128,)))\n",
        "    \n",
        "    ### YOUR CODE HERE: define decoder as per instructions above ###\n",
        "decoder.add(tensorflow.keras.layers.Dense(2*2*256))\n",
        "decoder.add(tensorflow.keras.layers.Reshape((2, 2, 256)))\n",
        "decoder.add(tensorflow.keras.layers.Conv2DTranspose(filters=128, kernel_size=(3, 3), strides=2, activation='relu', padding='same'))\n",
        "decoder.add(tensorflow.keras.layers.Conv2DTranspose(filters=64, kernel_size=(3, 3), strides=2, activation='relu', padding='same'))\n",
        "decoder.add(tensorflow.keras.layers.Conv2DTranspose(filters=32, kernel_size=(3, 3), strides=2, activation='relu', padding='same'))\n",
        "decoder.add(tensorflow.keras.layers.Conv2DTranspose(filters=3, kernel_size=(3, 3), strides=2, activation=None, padding='same'))\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Ry7-B9yXMuHQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "inp = tensorflow.keras.layers.Input((32,32,3))\n",
        "code = encoder(inp)\n",
        "reconstruction = decoder(code)\n",
        "\n",
        "autoencoder = tensorflow.keras.models.Model(inp,reconstruction)\n",
        "autoencoder.compile('adamax','mse')\n",
        "plt.imshow(imgs[5])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "TzwYW41zNA56",
        "outputId": "d4ec28f2-89cb-41db-feed-a4d2e7150e8a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7efff42ebbd0>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "autoencoder.fit(x=imgs,y=imgs,epochs=15, validation_split=0.3, batch_size=70, verbose=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzmKcuX_Qegd",
        "outputId": "7c30bbcd-718d-4469-eafa-d83b90ad16cc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/15\n",
            "301/301 [==============================] - 86s 281ms/step - loss: 2587.0002 - val_loss: 1443.7454\n",
            "Epoch 2/15\n",
            "301/301 [==============================] - 85s 282ms/step - loss: 1067.6146 - val_loss: 1076.6849\n",
            "Epoch 3/15\n",
            "301/301 [==============================] - 84s 279ms/step - loss: 807.5678 - val_loss: 911.9669\n",
            "Epoch 4/15\n",
            "301/301 [==============================] - 88s 292ms/step - loss: 687.9883 - val_loss: 796.1129\n",
            "Epoch 5/15\n",
            "301/301 [==============================] - 85s 281ms/step - loss: 619.1125 - val_loss: 732.4547\n",
            "Epoch 6/15\n",
            "301/301 [==============================] - 85s 282ms/step - loss: 566.8257 - val_loss: 701.3790\n",
            "Epoch 7/15\n",
            "301/301 [==============================] - 85s 282ms/step - loss: 536.6190 - val_loss: 654.6635\n",
            "Epoch 8/15\n",
            "301/301 [==============================] - 84s 280ms/step - loss: 506.5219 - val_loss: 625.6414\n",
            "Epoch 9/15\n",
            "301/301 [==============================] - 84s 278ms/step - loss: 484.8022 - val_loss: 597.5538\n",
            "Epoch 10/15\n",
            "301/301 [==============================] - 84s 279ms/step - loss: 456.8487 - val_loss: 578.3728\n",
            "Epoch 11/15\n",
            "301/301 [==============================] - 88s 292ms/step - loss: 441.7135 - val_loss: 557.5455\n",
            "Epoch 12/15\n",
            "301/301 [==============================] - 85s 283ms/step - loss: 425.4960 - val_loss: 542.8338\n",
            "Epoch 13/15\n",
            "301/301 [==============================] - 89s 297ms/step - loss: 412.9218 - val_loss: 524.1076\n",
            "Epoch 14/15\n",
            "301/301 [==============================] - 86s 285ms/step - loss: 398.2659 - val_loss: 508.0206\n",
            "Epoch 15/15\n",
            "301/301 [==============================] - 85s 284ms/step - loss: 386.8775 - val_loss: 495.3129\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7efff42d4cd0>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = autoencoder.predict(imgs[2].reshape(-1,32,32,3))\n",
        "# plt.imshow(y[0])\n",
        "bottle_neck=[]\n",
        "for i in range(len(imgs)):\n",
        "  inp = encoder(imgs[i].reshape(-1,32,32,3))\n",
        "  bottle_neck.append(inp[0])\n",
        "print(len(bottle_neck))\n",
        "# plt.imshow(X[0].reshape(-1,32,32,3))\n",
        "print(np.array(bottle_neck))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JINqvzZLNS5v",
        "outputId": "041a59ca-09de-4f57-a4b2-98baea929b2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1/1 [==============================] - 0s 148ms/step\n",
            "30082\n",
            "[[-229.28946   199.0799      8.26963  ... -335.09348    84.2735\n",
            "     8.904257]\n",
            " [-279.6001     99.45916  -193.0558   ...  -79.30201   244.63995\n",
            "    56.268776]\n",
            " [-209.89159    34.440144 -273.529    ... -109.87807   -20.743443\n",
            "   -39.56185 ]\n",
            " ...\n",
            " [ 535.3886    682.105      34.338326 ...   73.36366    51.362183\n",
            "   198.61774 ]\n",
            " [  27.780231  119.5717    -89.66055  ... -103.63884    48.72152\n",
            "   137.72275 ]\n",
            " [-186.72784   131.93314  -302.78754  ... -289.20102   -15.888614\n",
            "    61.178284]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Checkpoints:\n",
        "from keras.callbacks import ModelCheckpoint, TensorBoard\n",
        "checkpoints = []\n",
        "# epochs = 1\n",
        "# batch_size = 2000\n",
        "print(np.array(images).shape)\n",
        "imgs = np.array(images)\n",
        "# y_train = np.array(y_train)\n",
        "# X_test  = np.array(X_test)\n",
        "# y_test  = np.array(y_test)\n",
        "\n",
        "\n",
        "# from keras.preprocessing.image import ImageDataGenerator\n",
        "# generated_data = ImageDataGenerator(featurewise_center=False, samplewise_center=False, featurewise_std_normalization=False, samplewise_std_normalization=False, zca_whitening=False, rotation_range=0,  width_shift_range=0.1, height_shift_range=0.1, horizontal_flip = True, vertical_flip = False)\n",
        "# generated_data.fit(X_train)\n",
        "# print(np.array(y_train).shape)\n",
        "# autoencoder.fit_generator(generated_data.flow(X_train, X_train, batch_size=batch_size), steps_per_epoch=X_train.shape[0],epochs=epochs, validation_data=(X_test, X_test), callbacks=checkpoints)\n",
        "# Training Model:\n",
        "# autoencoder.fit(X_train, X_train, batch_size=batch_size, epochs=epochs, validation_data=(X_test, X_test), shuffle=True, callbacks=checkpoints)\n",
        "autoencoder.compile(optimizer='rmsprop', loss='mse')\n",
        "history = autoencoder.fit(\n",
        "      imgs,\n",
        "      imgs,\n",
        "      epochs=20, \n",
        "      batch_size=100, validation_split=0.10\n",
        "        )  "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m9tj3cu2Eo-D",
        "outputId": "69ffe3cb-02f2-47bc-8060-929fc6121c49"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(30082, 32, 32, 3)\n",
            "Epoch 1/20\n",
            "271/271 [==============================] - 102s 370ms/step - loss: 4811.3086 - val_loss: 1855.0262\n",
            "Epoch 2/20\n",
            "271/271 [==============================] - 95s 350ms/step - loss: 1784.9490 - val_loss: 2605.5378\n",
            "Epoch 3/20\n",
            "271/271 [==============================] - 92s 340ms/step - loss: 1378.5955 - val_loss: 946.9558\n",
            "Epoch 4/20\n",
            "271/271 [==============================] - 93s 343ms/step - loss: 1176.2596 - val_loss: 996.9766\n",
            "Epoch 5/20\n",
            "271/271 [==============================] - 93s 341ms/step - loss: 1044.7181 - val_loss: 963.6762\n",
            "Epoch 6/20\n",
            "271/271 [==============================] - 93s 342ms/step - loss: 951.3413 - val_loss: 1338.8054\n",
            "Epoch 7/20\n",
            "271/271 [==============================] - 92s 341ms/step - loss: 890.2167 - val_loss: 876.9851\n",
            "Epoch 8/20\n",
            "271/271 [==============================] - 92s 340ms/step - loss: 840.0347 - val_loss: 720.9719\n",
            "Epoch 9/20\n",
            "271/271 [==============================] - 92s 338ms/step - loss: 793.5652 - val_loss: 1199.3467\n",
            "Epoch 10/20\n",
            "271/271 [==============================] - 91s 336ms/step - loss: 763.3109 - val_loss: 1350.0077\n",
            "Epoch 11/20\n",
            "271/271 [==============================] - 92s 339ms/step - loss: 733.6337 - val_loss: 754.6826\n",
            "Epoch 12/20\n",
            "271/271 [==============================] - 92s 338ms/step - loss: 708.6763 - val_loss: 1170.6252\n",
            "Epoch 13/20\n",
            "271/271 [==============================] - 92s 338ms/step - loss: 686.3035 - val_loss: 784.0370\n",
            "Epoch 14/20\n",
            "271/271 [==============================] - 92s 338ms/step - loss: 666.7533 - val_loss: 623.4160\n",
            "Epoch 15/20\n",
            "271/271 [==============================] - 91s 338ms/step - loss: 652.7297 - val_loss: 770.6533\n",
            "Epoch 16/20\n",
            "271/271 [==============================] - 91s 335ms/step - loss: 638.1852 - val_loss: 538.0394\n",
            "Epoch 17/20\n",
            "271/271 [==============================] - 90s 332ms/step - loss: 629.3766 - val_loss: 619.7981\n",
            "Epoch 18/20\n",
            "271/271 [==============================] - 89s 330ms/step - loss: 611.5278 - val_loss: 661.2653\n",
            "Epoch 19/20\n",
            "271/271 [==============================] - 90s 331ms/step - loss: 600.6158 - val_loss: 683.0893\n",
            "Epoch 20/20\n",
            "271/271 [==============================] - 89s 330ms/step - loss: 589.3994 - val_loss: 671.3165\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y = autoencoder.predict(images[0].reshape(-1, 32, 32, 3))\n",
        "plt.imshow(cv2.cvtColor((y[0] * 255).astype(np.uint8), cv2.COLOR_BGR2RGB))\n",
        "# plt.imshow((y[0] * 255).astype(np.uint8))\n",
        "# print(y.shape)\n"
      ],
      "metadata": {
        "id": "uxZpGdsIZcGs"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}